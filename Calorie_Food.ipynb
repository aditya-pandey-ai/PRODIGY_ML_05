{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:19:56.894628Z",
     "start_time": "2024-05-28T21:19:54.161435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the path to the dataset\n",
    "data_dir = 'food-101/food-101'\n",
    "\n",
    "# ImageDataGenerator for Data Augmentation and Normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% of data used for validation\n",
    ")\n",
    "\n",
    "# Create training and validation generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Ensure class_mode is 'categorical' for multi-class classification\n",
    "    subset='training'  # Use this subset for training\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Ensure class_mode is 'categorical' for multi-class classification\n",
    "    subset='validation'  # Use this subset for validation\n",
    ")\n",
    "\n",
    "# Debugging: Print class indices\n",
    "print(train_generator.class_indices)\n",
    "print(f\"Number of classes: {len(train_generator.class_indices)}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80800 images belonging to 2 classes.\n",
      "Found 20200 images belonging to 2 classes.\n",
      "{'images': 0, 'meta': 1}\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:19:58.275618Z",
     "start_time": "2024-05-28T21:19:57.684263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Load the ResNet50 model with pre-trained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Ensure the output layer matches the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Debugging: Print the model summary\n",
    "model.summary()\n"
   ],
   "id": "5dfa0306b863fe9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001B[38;5;33mFunctional\u001B[0m)           │ ?                      │    \u001B[38;5;34m23,587,712\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m23,587,712\u001B[0m (89.98 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m23,587,712\u001B[0m (89.98 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T20:06:08.256476Z",
     "start_time": "2024-05-28T19:01:20.576081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ],
   "id": "d85c4c04c48ff932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2525/2525\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3887s\u001B[0m 2s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T20:34:51.745956Z",
     "start_time": "2024-05-28T20:25:02.190838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')\n"
   ],
   "id": "fb36f7a0a6659142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m632/632\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m589s\u001B[0m 932ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Validation Accuracy: 1.00\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:20:04.501071Z",
     "start_time": "2024-05-28T21:20:04.485410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Example dictionary of average calories per food category\n",
    "calorie_dict = {\n",
    "    'apple_pie': 237,\n",
    "    'baby_back_ribs': 290,\n",
    "    'baklava': 334,\n",
    "    'beef_carpaccio': 123,\n",
    "    'beef_tartare': 175,\n",
    "    'beet_salad': 74,\n",
    "    'beignets': 241,\n",
    "    'bibimbap': 490,\n",
    "    'bread_pudding': 298,\n",
    "    'breakfast_burrito': 305,\n",
    "    'bruschetta': 175,\n",
    "    'caesar_salad': 190,\n",
    "    'cannoli': 276,\n",
    "    'caprese_salad': 250,\n",
    "    'carrot_cake': 415,\n",
    "    'ceviche': 100,\n",
    "    'cheesecake': 321,\n",
    "    'cheese_plate': 200,\n",
    "    'chicken_curry': 280,\n",
    "    'chicken_quesadilla': 350,\n",
    "    'chicken_wings': 430,\n",
    "    'chocolate_cake': 352,\n",
    "    'chocolate_mousse': 350,\n",
    "    'churros': 237,\n",
    "    'clam_chowder': 200,\n",
    "    'club_sandwich': 320,\n",
    "    'crab_cakes': 220,\n",
    "    'creme_brulee': 330,\n",
    "    'croque_madame': 300,\n",
    "    'cup_cakes': 305,\n",
    "    'deviled_eggs': 200,\n",
    "    'donuts': 452,\n",
    "    'dumplings': 250,\n",
    "    'edamame': 121,\n",
    "    'eggs_benedict': 400,\n",
    "    'escargots': 220,\n",
    "    'falafel': 330,\n",
    "    'filet_mignon': 679,\n",
    "    'fish_and_chips': 600,\n",
    "    'foie_gras': 445,\n",
    "    'french_fries': 365,\n",
    "    'french_onion_soup': 369,\n",
    "    'french_toast': 450,\n",
    "    'fried_calamari': 150,\n",
    "    'fried_rice': 228,\n",
    "    'frozen_yogurt': 159,\n",
    "    'garlic_bread': 206,\n",
    "    'gnocchi': 250,\n",
    "    'greek_salad': 210,\n",
    "    'grilled_cheese_sandwich': 320,\n",
    "    'grilled_salmon': 400,\n",
    "    'guacamole': 160,\n",
    "    'gyoza': 180,\n",
    "    'hamburger': 354,\n",
    "    'hot_and_sour_soup': 70,\n",
    "    'hot_dog': 300,\n",
    "    'huevos_rancheros': 360,\n",
    "    'hummus': 166,\n",
    "    'ice_cream': 207,\n",
    "    'lasagna': 135,\n",
    "    'lobster_bisque': 270,\n",
    "    'lobster_roll_sandwich': 436,\n",
    "    'macaroni_and_cheese': 450,\n",
    "    'macarons': 70,\n",
    "    'miso_soup': 40,\n",
    "    'mussels': 146,\n",
    "    'nachos': 550,\n",
    "    'omelette': 154,\n",
    "    'onion_rings': 276,\n",
    "    'oysters': 50,\n",
    "    'pad_thai': 300,\n",
    "    'paella': 300,\n",
    "    'pancakes': 227,\n",
    "    'panna_cotta': 282,\n",
    "    'peking_duck': 337,\n",
    "    'pho': 400,\n",
    "    'pizza': 266,\n",
    "    'pork_chop': 340,\n",
    "    'poutine': 740,\n",
    "    'prime_rib': 400,\n",
    "    'pulled_pork_sandwich': 440,\n",
    "    'ramen': 436,\n",
    "    'ravioli': 320,\n",
    "    'red_velvet_cake': 370,\n",
    "    'risotto': 380,\n",
    "    'samosa': 262,\n",
    "    'sashimi': 231,\n",
    "    'scallops': 75,\n",
    "    'seaweed_salad': 70,\n",
    "    'shrimp_and_grits': 250,\n",
    "    'spaghetti_bolognese': 350,\n",
    "    'spaghetti_carbonara': 360,\n",
    "    'spring_rolls': 100,\n",
    "    'steak': 679,\n",
    "    'strawberry_shortcake': 275,\n",
    "    'sushi': 200,\n",
    "    'tacos': 226,\n",
    "    'takoyaki': 110,\n",
    "    'tiramisu': 240,\n",
    "    'tuna_tartare': 190,\n",
    "    'waffles': 291\n",
    "}\n",
    "\n",
    "# Function to estimate calories based on the predicted class\n",
    "def estimate_calories(predicted_class):\n",
    "    return calorie_dict.get(predicted_class, 0)  # Return 0 if the class is not found\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Create batch axis\n",
    "    return img_array / 255.0  # Normalize the image\n",
    "\n",
    "# Function to predict food item and estimate calories\n",
    "def predict_from_image(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(train_generator.class_indices.keys())[predicted_index]\n",
    "    calories = estimate_calories(predicted_class)\n",
    "    return predicted_class, calories\n",
    "\n",
    "# Function to capture image from webcam and predict\n",
    "def predict_from_camera(model, class_indices):\n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam (usually device 0)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Could not open the webcam.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image. Please try again.\")\n",
    "            continue\n",
    "        \n",
    "        cv2.imshow('Press \"c\" to capture', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the captured image\n",
    "    camera_image_path = 'captured_image.jpg'\n",
    "    if frame is not None and frame.size != 0:\n",
    "        cv2.imwrite(camera_image_path, frame)\n",
    "    else:\n",
    "        raise ValueError(\"Captured image is empty.\")\n",
    "\n",
    "    # Predict from the captured image\n",
    "    return predict_from_image(camera_image_path, model, class_indices)\n",
    "\n",
    "# Main function to predict calories\n",
    "def predict_calories(input_type, input_value=None):\n",
    "    if input_type == 'name':\n",
    "        calories = estimate_calories(input_value)\n",
    "        return input_value, calories\n",
    "    elif input_type == 'image':\n",
    "        if input_value is None:\n",
    "            raise ValueError(\"For image input, input_value must be the path to the image.\")\n",
    "        return predict_from_image(input_value)\n",
    "    elif input_type == 'camera':\n",
    "        return predict_from_camera()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input type. Choose from 'name', 'image', or 'camera'.\")\n"
   ],
   "id": "b0764f4f4c58ff88",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T21:20:05.301384Z",
     "start_time": "2024-05-28T21:20:05.298641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "food_name = 'apple_pie'\n",
    "predicted_class, calories = predict_calories('name', food_name)\n",
    "print(f'Predicted food item: {predicted_class}, Estimated calories: {calories}')"
   ],
   "id": "1f7d70c65e1120a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted food item: apple_pie, Estimated calories: 237\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c5d50a8ecdbc323e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
